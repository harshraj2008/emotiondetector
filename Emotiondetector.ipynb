{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b4def418-1e5a-4df3-83c7-135bbffce68e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import to_categorical\n",
    "\n",
    "from keras_preprocessing.image import load_img\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Conv2D, Dropout, Flatten, MaxPooling2D\n",
    "import os\n",
    "from tqdm.notebook import tqdm\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from keras.models import model_from_json\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "aa8f2fa0-b4bc-4cd1-a6da-3d8620712c63",
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_DIR = \"images\\\\Train\"\n",
    "VALID_DIR = \"images\\\\Validation\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8b3c81e6-cf54-4594-87e0-dc6c1f478f5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                    image     label\n",
      "0       images\\Validation\\angry\\10052.jpg     angry\n",
      "1       images\\Validation\\angry\\10065.jpg     angry\n",
      "2       images\\Validation\\angry\\10079.jpg     angry\n",
      "3       images\\Validation\\angry\\10095.jpg     angry\n",
      "4       images\\Validation\\angry\\10121.jpg     angry\n",
      "...                                   ...       ...\n",
      "7061  images\\Validation\\surprise\\9806.jpg  surprise\n",
      "7062  images\\Validation\\surprise\\9830.jpg  surprise\n",
      "7063  images\\Validation\\surprise\\9853.jpg  surprise\n",
      "7064  images\\Validation\\surprise\\9878.jpg  surprise\n",
      "7065   images\\Validation\\surprise\\993.jpg  surprise\n",
      "\n",
      "[7066 rows x 2 columns]\n",
      "                                image     label\n",
      "0            images\\Train\\angry\\0.jpg     angry\n",
      "1            images\\Train\\angry\\1.jpg     angry\n",
      "2           images\\Train\\angry\\10.jpg     angry\n",
      "3        images\\Train\\angry\\10002.jpg     angry\n",
      "4        images\\Train\\angry\\10016.jpg     angry\n",
      "...                               ...       ...\n",
      "28816  images\\Train\\surprise\\9969.jpg  surprise\n",
      "28817  images\\Train\\surprise\\9985.jpg  surprise\n",
      "28818  images\\Train\\surprise\\9990.jpg  surprise\n",
      "28819  images\\Train\\surprise\\9992.jpg  surprise\n",
      "28820  images\\Train\\surprise\\9996.jpg  surprise\n",
      "\n",
      "[28821 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "#creates dataframe with foldername  and fetches the respective picture path \n",
    "def createsdataframe(dir):\n",
    "    image_paths = []\n",
    "    labels = []\n",
    "    for label in os.listdir(dir):\n",
    "        for imagename in os.listdir(os.path.join(dir, label)):\n",
    "            image_paths.append(os.path.join(dir, label, imagename))\n",
    "            labels.append(label)\n",
    "    return image_paths, labels\n",
    "train=pd.DataFrame()\n",
    "train['image'],train['label']= createsdataframe(VALID_DIR)\n",
    "print(train)\n",
    "test=pd.DataFrame()\n",
    "test['image'],test['label']= createsdataframe(TRAIN_DIR)\n",
    "print(test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b4f4fa52-9bfb-47bd-8bbe-08ff2c35c3cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d6a9961e914945e6aa63f28f760ab771",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7066 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0748e50b6a824b93999f146848465496",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/28821 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def extract_features(images):\n",
    "    features = []\n",
    "    for image in tqdm(images):\n",
    "        img = load_img(image,color_mode = \"grayscale\")\n",
    "        img = np.array(img)\n",
    "        features.append(img)\n",
    "    features = np.array(features)\n",
    "    features = features.reshape(len(features),48,48,1)\n",
    "    return features\n",
    "train_features=extract_features(train['image'])\n",
    "test_features=extract_features(test['image'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cce2e2b6-eb5f-4ee4-8306-29583d86bfcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train=train_features/255.0\n",
    "x_test=test_features/255.0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7a228b47-06b5-49c6-9d29-b2d8833347c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: black;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-1 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-1 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-1 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-1 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 1ex;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-1 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LabelEncoder()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;LabelEncoder<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.4/modules/generated/sklearn.preprocessing.LabelEncoder.html\">?<span>Documentation for LabelEncoder</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>LabelEncoder()</pre></div> </div></div></div></div>"
      ],
      "text/plain": [
       "LabelEncoder()"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "le=LabelEncoder()\n",
    "le.fit(train['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6f0a550e-2f78-4820-9a57-1e340c1c560c",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train=le.transform(train['label'])\n",
    "y_test=le.transform(test['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ee93586c-399f-40c3-969f-a9bd377fe358",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train=to_categorical(y_train,num_classes=7)\n",
    "y_test=to_categorical(y_test,num_classes=7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "464cae64-b6b1-443f-b1a7-be599a6ada6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Hk200\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:99: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(\n"
     ]
    }
   ],
   "source": [
    "model= Sequential()\n",
    "model.add(Conv2D(128, kernel_size=(3,3), activation='relu', input_shape=(48,48,1)))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.4))\n",
    "\n",
    "model.add(Conv2D(256, kernel_size=(3,3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.4))\n",
    "\n",
    "model.add(Conv2D(512, kernel_size=(3,3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.4))\n",
    "\n",
    "model.add(Conv2D(512, kernel_size=(3,3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.4))\n",
    "\n",
    "model.add(Flatten())\n",
    "# fully connected layers\n",
    "model.add(Dense(512, activation='relu'))\n",
    "model.add(Dropout(0.4))\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dropout(0.3))\n",
    "# output layer\n",
    "model.add(Dense(7, activation='softmax'))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5efbeb8e-f416-404c-8ae5-a79d5aede2ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m71s\u001b[0m 1s/step - accuracy: 0.2382 - loss: 1.8564 - val_accuracy: 0.2486 - val_loss: 1.8161\n",
      "Epoch 2/200\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m88s\u001b[0m 2s/step - accuracy: 0.2540 - loss: 1.8177 - val_accuracy: 0.2486 - val_loss: 1.8225\n",
      "Epoch 3/200\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m67s\u001b[0m 1s/step - accuracy: 0.2571 - loss: 1.8177 - val_accuracy: 0.2486 - val_loss: 1.8168\n",
      "Epoch 4/200\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m108s\u001b[0m 2s/step - accuracy: 0.2596 - loss: 1.8205 - val_accuracy: 0.2486 - val_loss: 1.8126\n",
      "Epoch 5/200\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m100s\u001b[0m 2s/step - accuracy: 0.2636 - loss: 1.8132 - val_accuracy: 0.2486 - val_loss: 1.8135\n",
      "Epoch 6/200\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 938ms/step - accuracy: 0.2640 - loss: 1.8114 - val_accuracy: 0.2486 - val_loss: 1.8140\n",
      "Epoch 7/200\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 978ms/step - accuracy: 0.2591 - loss: 1.8142 - val_accuracy: 0.2486 - val_loss: 1.8132\n",
      "Epoch 8/200\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 942ms/step - accuracy: 0.2515 - loss: 1.8150 - val_accuracy: 0.2486 - val_loss: 1.8132\n",
      "Epoch 9/200\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 1s/step - accuracy: 0.2546 - loss: 1.8112 - val_accuracy: 0.2579 - val_loss: 1.8059\n",
      "Epoch 10/200\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 934ms/step - accuracy: 0.2611 - loss: 1.7961 - val_accuracy: 0.2486 - val_loss: 1.7909\n",
      "Epoch 11/200\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 923ms/step - accuracy: 0.2700 - loss: 1.7800 - val_accuracy: 0.2528 - val_loss: 1.7632\n",
      "Epoch 12/200\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 930ms/step - accuracy: 0.2768 - loss: 1.7450 - val_accuracy: 0.2999 - val_loss: 1.7097\n",
      "Epoch 13/200\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 918ms/step - accuracy: 0.3022 - loss: 1.7151 - val_accuracy: 0.2984 - val_loss: 1.7136\n",
      "Epoch 14/200\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 925ms/step - accuracy: 0.3139 - loss: 1.6909 - val_accuracy: 0.3220 - val_loss: 1.6653\n",
      "Epoch 15/200\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 920ms/step - accuracy: 0.3253 - loss: 1.6763 - val_accuracy: 0.3434 - val_loss: 1.6299\n",
      "Epoch 16/200\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 921ms/step - accuracy: 0.3462 - loss: 1.6470 - val_accuracy: 0.3490 - val_loss: 1.6283\n",
      "Epoch 17/200\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 931ms/step - accuracy: 0.3707 - loss: 1.6072 - val_accuracy: 0.3763 - val_loss: 1.5806\n",
      "Epoch 18/200\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m144s\u001b[0m 3s/step - accuracy: 0.3848 - loss: 1.5708 - val_accuracy: 0.4040 - val_loss: 1.5311\n",
      "Epoch 19/200\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 917ms/step - accuracy: 0.4021 - loss: 1.5546 - val_accuracy: 0.4130 - val_loss: 1.4925\n",
      "Epoch 20/200\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 929ms/step - accuracy: 0.4173 - loss: 1.5250 - val_accuracy: 0.4222 - val_loss: 1.4790\n",
      "Epoch 21/200\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 933ms/step - accuracy: 0.4254 - loss: 1.4863 - val_accuracy: 0.4256 - val_loss: 1.4635\n",
      "Epoch 22/200\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 928ms/step - accuracy: 0.4262 - loss: 1.4717 - val_accuracy: 0.4528 - val_loss: 1.4128\n",
      "Epoch 23/200\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 925ms/step - accuracy: 0.4584 - loss: 1.4232 - val_accuracy: 0.4449 - val_loss: 1.4182\n",
      "Epoch 24/200\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 926ms/step - accuracy: 0.4511 - loss: 1.4037 - val_accuracy: 0.4326 - val_loss: 1.4372\n",
      "Epoch 25/200\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 925ms/step - accuracy: 0.4592 - loss: 1.4031 - val_accuracy: 0.4505 - val_loss: 1.4107\n",
      "Epoch 26/200\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 922ms/step - accuracy: 0.4744 - loss: 1.3682 - val_accuracy: 0.4741 - val_loss: 1.3566\n",
      "Epoch 27/200\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 926ms/step - accuracy: 0.4963 - loss: 1.3103 - val_accuracy: 0.4829 - val_loss: 1.3414\n",
      "Epoch 28/200\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 924ms/step - accuracy: 0.4920 - loss: 1.3352 - val_accuracy: 0.4858 - val_loss: 1.3347\n",
      "Epoch 29/200\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 927ms/step - accuracy: 0.4905 - loss: 1.3305 - val_accuracy: 0.4909 - val_loss: 1.3305\n",
      "Epoch 30/200\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 927ms/step - accuracy: 0.5088 - loss: 1.2999 - val_accuracy: 0.4893 - val_loss: 1.3223\n",
      "Epoch 31/200\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 933ms/step - accuracy: 0.5262 - loss: 1.2476 - val_accuracy: 0.4951 - val_loss: 1.3143\n",
      "Epoch 32/200\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 926ms/step - accuracy: 0.5286 - loss: 1.2555 - val_accuracy: 0.4954 - val_loss: 1.3106\n",
      "Epoch 33/200\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 920ms/step - accuracy: 0.5331 - loss: 1.2231 - val_accuracy: 0.5085 - val_loss: 1.2910\n",
      "Epoch 34/200\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 919ms/step - accuracy: 0.5371 - loss: 1.2113 - val_accuracy: 0.5099 - val_loss: 1.2874\n",
      "Epoch 35/200\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 922ms/step - accuracy: 0.5574 - loss: 1.1824 - val_accuracy: 0.5091 - val_loss: 1.2865\n",
      "Epoch 36/200\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 920ms/step - accuracy: 0.5688 - loss: 1.1569 - val_accuracy: 0.5095 - val_loss: 1.2943\n",
      "Epoch 37/200\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 919ms/step - accuracy: 0.5611 - loss: 1.1442 - val_accuracy: 0.5153 - val_loss: 1.2835\n",
      "Epoch 38/200\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 923ms/step - accuracy: 0.5861 - loss: 1.1046 - val_accuracy: 0.5098 - val_loss: 1.2949\n",
      "Epoch 39/200\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 924ms/step - accuracy: 0.5847 - loss: 1.1176 - val_accuracy: 0.5176 - val_loss: 1.2812\n",
      "Epoch 40/200\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 920ms/step - accuracy: 0.5828 - loss: 1.0929 - val_accuracy: 0.5167 - val_loss: 1.2803\n",
      "Epoch 41/200\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 918ms/step - accuracy: 0.5982 - loss: 1.0563 - val_accuracy: 0.5265 - val_loss: 1.2663\n",
      "Epoch 42/200\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 922ms/step - accuracy: 0.6150 - loss: 1.0385 - val_accuracy: 0.5208 - val_loss: 1.2721\n",
      "Epoch 43/200\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 920ms/step - accuracy: 0.6088 - loss: 1.0565 - val_accuracy: 0.5273 - val_loss: 1.2748\n",
      "Epoch 44/200\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 919ms/step - accuracy: 0.6176 - loss: 1.0363 - val_accuracy: 0.5282 - val_loss: 1.2647\n",
      "Epoch 45/200\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 920ms/step - accuracy: 0.6261 - loss: 1.0154 - val_accuracy: 0.5294 - val_loss: 1.2649\n",
      "Epoch 46/200\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 919ms/step - accuracy: 0.6283 - loss: 1.0063 - val_accuracy: 0.5262 - val_loss: 1.2764\n",
      "Epoch 47/200\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 919ms/step - accuracy: 0.6349 - loss: 0.9980 - val_accuracy: 0.5274 - val_loss: 1.2735\n",
      "Epoch 48/200\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 920ms/step - accuracy: 0.6413 - loss: 0.9537 - val_accuracy: 0.5255 - val_loss: 1.2852\n",
      "Epoch 49/200\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 919ms/step - accuracy: 0.6487 - loss: 0.9379 - val_accuracy: 0.5272 - val_loss: 1.2891\n",
      "Epoch 50/200\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 923ms/step - accuracy: 0.6613 - loss: 0.9210 - val_accuracy: 0.5268 - val_loss: 1.2889\n",
      "Epoch 51/200\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 930ms/step - accuracy: 0.6690 - loss: 0.8909 - val_accuracy: 0.5287 - val_loss: 1.2883\n",
      "Epoch 52/200\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 922ms/step - accuracy: 0.6628 - loss: 0.9220 - val_accuracy: 0.5299 - val_loss: 1.2853\n",
      "Epoch 53/200\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 923ms/step - accuracy: 0.6692 - loss: 0.8959 - val_accuracy: 0.5266 - val_loss: 1.2922\n",
      "Epoch 54/200\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 928ms/step - accuracy: 0.6827 - loss: 0.8608 - val_accuracy: 0.5274 - val_loss: 1.2985\n",
      "Epoch 55/200\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 962ms/step - accuracy: 0.6810 - loss: 0.8611 - val_accuracy: 0.5248 - val_loss: 1.3255\n",
      "Epoch 56/200\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 945ms/step - accuracy: 0.6820 - loss: 0.8674 - val_accuracy: 0.5312 - val_loss: 1.3247\n",
      "Epoch 57/200\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 963ms/step - accuracy: 0.6767 - loss: 0.8702 - val_accuracy: 0.5276 - val_loss: 1.3237\n",
      "Epoch 58/200\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 970ms/step - accuracy: 0.7055 - loss: 0.8128 - val_accuracy: 0.5281 - val_loss: 1.3277\n",
      "Epoch 59/200\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 978ms/step - accuracy: 0.6913 - loss: 0.8322 - val_accuracy: 0.5308 - val_loss: 1.3254\n",
      "Epoch 60/200\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 987ms/step - accuracy: 0.7059 - loss: 0.8023 - val_accuracy: 0.5327 - val_loss: 1.3229\n",
      "Epoch 61/200\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 993ms/step - accuracy: 0.7225 - loss: 0.7815 - val_accuracy: 0.5271 - val_loss: 1.3312\n",
      "Epoch 62/200\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 987ms/step - accuracy: 0.7115 - loss: 0.7879 - val_accuracy: 0.5232 - val_loss: 1.3569\n",
      "Epoch 63/200\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 987ms/step - accuracy: 0.7201 - loss: 0.7783 - val_accuracy: 0.5259 - val_loss: 1.3311\n",
      "Epoch 64/200\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 996ms/step - accuracy: 0.7335 - loss: 0.7300 - val_accuracy: 0.5294 - val_loss: 1.3533\n",
      "Epoch 65/200\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 999ms/step - accuracy: 0.7363 - loss: 0.7406 - val_accuracy: 0.5236 - val_loss: 1.3547\n",
      "Epoch 66/200\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 998ms/step - accuracy: 0.7419 - loss: 0.7115 - val_accuracy: 0.5318 - val_loss: 1.3505\n",
      "Epoch 67/200\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 1s/step - accuracy: 0.7419 - loss: 0.7173 - val_accuracy: 0.5319 - val_loss: 1.3561\n",
      "Epoch 68/200\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 1s/step - accuracy: 0.7435 - loss: 0.7112 - val_accuracy: 0.5241 - val_loss: 1.3945\n",
      "Epoch 69/200\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 1s/step - accuracy: 0.7483 - loss: 0.6919 - val_accuracy: 0.5239 - val_loss: 1.4150\n",
      "Epoch 70/200\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 1s/step - accuracy: 0.7564 - loss: 0.6612 - val_accuracy: 0.5284 - val_loss: 1.3766\n",
      "Epoch 71/200\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 1s/step - accuracy: 0.7670 - loss: 0.6814 - val_accuracy: 0.5317 - val_loss: 1.3804\n",
      "Epoch 72/200\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 1s/step - accuracy: 0.7608 - loss: 0.6779 - val_accuracy: 0.5299 - val_loss: 1.3790\n",
      "Epoch 73/200\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 1s/step - accuracy: 0.7696 - loss: 0.6459 - val_accuracy: 0.5287 - val_loss: 1.4017\n",
      "Epoch 74/200\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 1s/step - accuracy: 0.7650 - loss: 0.6512 - val_accuracy: 0.5292 - val_loss: 1.3970\n",
      "Epoch 75/200\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 1s/step - accuracy: 0.7692 - loss: 0.6295 - val_accuracy: 0.5297 - val_loss: 1.4287\n",
      "Epoch 76/200\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 1s/step - accuracy: 0.7805 - loss: 0.6173 - val_accuracy: 0.5269 - val_loss: 1.4055\n",
      "Epoch 77/200\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 1s/step - accuracy: 0.7762 - loss: 0.6270 - val_accuracy: 0.5290 - val_loss: 1.4228\n",
      "Epoch 78/200\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 1s/step - accuracy: 0.7860 - loss: 0.5997 - val_accuracy: 0.5278 - val_loss: 1.4232\n",
      "Epoch 79/200\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 1s/step - accuracy: 0.7838 - loss: 0.5951 - val_accuracy: 0.5295 - val_loss: 1.4220\n",
      "Epoch 80/200\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 1s/step - accuracy: 0.7882 - loss: 0.5948 - val_accuracy: 0.5317 - val_loss: 1.4511\n",
      "Epoch 81/200\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 1s/step - accuracy: 0.7982 - loss: 0.5476 - val_accuracy: 0.5290 - val_loss: 1.4540\n",
      "Epoch 82/200\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 1s/step - accuracy: 0.7925 - loss: 0.5683 - val_accuracy: 0.5343 - val_loss: 1.4656\n",
      "Epoch 83/200\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 1s/step - accuracy: 0.7955 - loss: 0.5822 - val_accuracy: 0.5328 - val_loss: 1.4539\n",
      "Epoch 84/200\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 1s/step - accuracy: 0.8023 - loss: 0.5722 - val_accuracy: 0.5365 - val_loss: 1.4460\n",
      "Epoch 85/200\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 1s/step - accuracy: 0.8063 - loss: 0.5368 - val_accuracy: 0.5335 - val_loss: 1.4494\n",
      "Epoch 86/200\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 1s/step - accuracy: 0.8175 - loss: 0.5291 - val_accuracy: 0.5333 - val_loss: 1.4189\n",
      "Epoch 87/200\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 1s/step - accuracy: 0.8191 - loss: 0.5234 - val_accuracy: 0.5273 - val_loss: 1.4718\n",
      "Epoch 88/200\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 1s/step - accuracy: 0.8152 - loss: 0.5121 - val_accuracy: 0.5326 - val_loss: 1.4393\n",
      "Epoch 89/200\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 998ms/step - accuracy: 0.8197 - loss: 0.5042 - val_accuracy: 0.5350 - val_loss: 1.4777\n",
      "Epoch 90/200\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 978ms/step - accuracy: 0.8183 - loss: 0.5255 - val_accuracy: 0.5255 - val_loss: 1.4856\n",
      "Epoch 91/200\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 979ms/step - accuracy: 0.8166 - loss: 0.5127 - val_accuracy: 0.5352 - val_loss: 1.5107\n",
      "Epoch 92/200\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 975ms/step - accuracy: 0.8220 - loss: 0.5071 - val_accuracy: 0.5352 - val_loss: 1.4808\n",
      "Epoch 93/200\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 973ms/step - accuracy: 0.8225 - loss: 0.5129 - val_accuracy: 0.5296 - val_loss: 1.4738\n",
      "Epoch 94/200\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 967ms/step - accuracy: 0.8350 - loss: 0.4693 - val_accuracy: 0.5315 - val_loss: 1.5456\n",
      "Epoch 95/200\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 965ms/step - accuracy: 0.8389 - loss: 0.4685 - val_accuracy: 0.5330 - val_loss: 1.5000\n",
      "Epoch 96/200\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 965ms/step - accuracy: 0.8354 - loss: 0.4731 - val_accuracy: 0.5356 - val_loss: 1.5050\n",
      "Epoch 97/200\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 966ms/step - accuracy: 0.8326 - loss: 0.4706 - val_accuracy: 0.5324 - val_loss: 1.5010\n",
      "Epoch 98/200\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 966ms/step - accuracy: 0.8381 - loss: 0.4451 - val_accuracy: 0.5353 - val_loss: 1.5552\n",
      "Epoch 99/200\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 967ms/step - accuracy: 0.8389 - loss: 0.4652 - val_accuracy: 0.5391 - val_loss: 1.5235\n",
      "Epoch 100/200\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 965ms/step - accuracy: 0.8533 - loss: 0.4307 - val_accuracy: 0.5319 - val_loss: 1.5508\n",
      "Epoch 101/200\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 962ms/step - accuracy: 0.8457 - loss: 0.4420 - val_accuracy: 0.5346 - val_loss: 1.5564\n",
      "Epoch 102/200\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 963ms/step - accuracy: 0.8484 - loss: 0.4328 - val_accuracy: 0.5321 - val_loss: 1.5422\n",
      "Epoch 103/200\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 963ms/step - accuracy: 0.8518 - loss: 0.4201 - val_accuracy: 0.5258 - val_loss: 1.5365\n",
      "Epoch 104/200\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 967ms/step - accuracy: 0.8435 - loss: 0.4417 - val_accuracy: 0.5326 - val_loss: 1.5347\n",
      "Epoch 105/200\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 965ms/step - accuracy: 0.8579 - loss: 0.3979 - val_accuracy: 0.5300 - val_loss: 1.5961\n",
      "Epoch 106/200\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 967ms/step - accuracy: 0.8529 - loss: 0.4180 - val_accuracy: 0.5303 - val_loss: 1.5242\n",
      "Epoch 107/200\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 964ms/step - accuracy: 0.8530 - loss: 0.4206 - val_accuracy: 0.5318 - val_loss: 1.5392\n",
      "Epoch 108/200\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 965ms/step - accuracy: 0.8523 - loss: 0.4120 - val_accuracy: 0.5333 - val_loss: 1.5998\n",
      "Epoch 109/200\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 960ms/step - accuracy: 0.8643 - loss: 0.3950 - val_accuracy: 0.5316 - val_loss: 1.5715\n",
      "Epoch 110/200\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 966ms/step - accuracy: 0.8658 - loss: 0.3947 - val_accuracy: 0.5354 - val_loss: 1.5893\n",
      "Epoch 111/200\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 966ms/step - accuracy: 0.8645 - loss: 0.3965 - val_accuracy: 0.5313 - val_loss: 1.5997\n",
      "Epoch 112/200\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 964ms/step - accuracy: 0.8716 - loss: 0.3750 - val_accuracy: 0.5339 - val_loss: 1.6219\n",
      "Epoch 113/200\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 962ms/step - accuracy: 0.8592 - loss: 0.4001 - val_accuracy: 0.5287 - val_loss: 1.5424\n",
      "Epoch 114/200\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 966ms/step - accuracy: 0.8637 - loss: 0.4050 - val_accuracy: 0.5312 - val_loss: 1.6097\n",
      "Epoch 115/200\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 964ms/step - accuracy: 0.8627 - loss: 0.3823 - val_accuracy: 0.5304 - val_loss: 1.6322\n",
      "Epoch 116/200\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 967ms/step - accuracy: 0.8709 - loss: 0.3587 - val_accuracy: 0.5289 - val_loss: 1.6712\n",
      "Epoch 117/200\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 969ms/step - accuracy: 0.8766 - loss: 0.3450 - val_accuracy: 0.5263 - val_loss: 1.6446\n",
      "Epoch 118/200\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 966ms/step - accuracy: 0.8652 - loss: 0.3826 - val_accuracy: 0.5330 - val_loss: 1.6473\n",
      "Epoch 119/200\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 965ms/step - accuracy: 0.8673 - loss: 0.3739 - val_accuracy: 0.5274 - val_loss: 1.5986\n",
      "Epoch 120/200\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 965ms/step - accuracy: 0.8750 - loss: 0.3707 - val_accuracy: 0.5336 - val_loss: 1.6324\n",
      "Epoch 121/200\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 964ms/step - accuracy: 0.8713 - loss: 0.3636 - val_accuracy: 0.5296 - val_loss: 1.6241\n",
      "Epoch 122/200\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 961ms/step - accuracy: 0.8885 - loss: 0.3271 - val_accuracy: 0.5288 - val_loss: 1.7014\n",
      "Epoch 123/200\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 958ms/step - accuracy: 0.8662 - loss: 0.3710 - val_accuracy: 0.5349 - val_loss: 1.6606\n",
      "Epoch 124/200\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 963ms/step - accuracy: 0.8820 - loss: 0.3336 - val_accuracy: 0.5295 - val_loss: 1.6669\n",
      "Epoch 125/200\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 960ms/step - accuracy: 0.8800 - loss: 0.3435 - val_accuracy: 0.5336 - val_loss: 1.6814\n",
      "Epoch 126/200\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 963ms/step - accuracy: 0.8989 - loss: 0.3073 - val_accuracy: 0.5283 - val_loss: 1.6862\n",
      "Epoch 127/200\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 968ms/step - accuracy: 0.8815 - loss: 0.3432 - val_accuracy: 0.5311 - val_loss: 1.6525\n",
      "Epoch 128/200\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 966ms/step - accuracy: 0.8878 - loss: 0.3366 - val_accuracy: 0.5270 - val_loss: 1.6635\n",
      "Epoch 129/200\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 961ms/step - accuracy: 0.8829 - loss: 0.3436 - val_accuracy: 0.5348 - val_loss: 1.6831\n",
      "Epoch 130/200\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 965ms/step - accuracy: 0.8858 - loss: 0.3254 - val_accuracy: 0.5317 - val_loss: 1.7138\n",
      "Epoch 131/200\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 963ms/step - accuracy: 0.8961 - loss: 0.3093 - val_accuracy: 0.5342 - val_loss: 1.6243\n",
      "Epoch 132/200\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 965ms/step - accuracy: 0.8843 - loss: 0.3285 - val_accuracy: 0.5307 - val_loss: 1.6605\n",
      "Epoch 133/200\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 966ms/step - accuracy: 0.8847 - loss: 0.3226 - val_accuracy: 0.5309 - val_loss: 1.6998\n",
      "Epoch 134/200\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 967ms/step - accuracy: 0.8954 - loss: 0.3192 - val_accuracy: 0.5327 - val_loss: 1.7008\n",
      "Epoch 135/200\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 961ms/step - accuracy: 0.8982 - loss: 0.2966 - val_accuracy: 0.5296 - val_loss: 1.7639\n",
      "Epoch 136/200\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 961ms/step - accuracy: 0.9006 - loss: 0.2877 - val_accuracy: 0.5342 - val_loss: 1.7486\n",
      "Epoch 137/200\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 961ms/step - accuracy: 0.9008 - loss: 0.2998 - val_accuracy: 0.5261 - val_loss: 1.7227\n",
      "Epoch 138/200\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 961ms/step - accuracy: 0.8927 - loss: 0.3250 - val_accuracy: 0.5247 - val_loss: 1.6720\n",
      "Epoch 139/200\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 963ms/step - accuracy: 0.8936 - loss: 0.3018 - val_accuracy: 0.5304 - val_loss: 1.7025\n",
      "Epoch 140/200\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 965ms/step - accuracy: 0.8956 - loss: 0.3034 - val_accuracy: 0.5301 - val_loss: 1.6911\n",
      "Epoch 141/200\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 964ms/step - accuracy: 0.9023 - loss: 0.2932 - val_accuracy: 0.5298 - val_loss: 1.7039\n",
      "Epoch 142/200\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 958ms/step - accuracy: 0.8949 - loss: 0.3087 - val_accuracy: 0.5341 - val_loss: 1.6554\n",
      "Epoch 143/200\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 950ms/step - accuracy: 0.8967 - loss: 0.2896 - val_accuracy: 0.5274 - val_loss: 1.7539\n",
      "Epoch 144/200\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 953ms/step - accuracy: 0.8816 - loss: 0.3389 - val_accuracy: 0.5324 - val_loss: 1.7281\n",
      "Epoch 145/200\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 958ms/step - accuracy: 0.9004 - loss: 0.3024 - val_accuracy: 0.5296 - val_loss: 1.7773\n",
      "Epoch 146/200\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 958ms/step - accuracy: 0.8939 - loss: 0.3045 - val_accuracy: 0.5231 - val_loss: 1.7611\n",
      "Epoch 147/200\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 962ms/step - accuracy: 0.8976 - loss: 0.3055 - val_accuracy: 0.5259 - val_loss: 1.7630\n",
      "Epoch 148/200\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 957ms/step - accuracy: 0.9053 - loss: 0.2777 - val_accuracy: 0.5321 - val_loss: 1.7726\n",
      "Epoch 149/200\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 952ms/step - accuracy: 0.9071 - loss: 0.2803 - val_accuracy: 0.5318 - val_loss: 1.7987\n",
      "Epoch 150/200\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 949ms/step - accuracy: 0.9053 - loss: 0.2973 - val_accuracy: 0.5313 - val_loss: 1.7831\n",
      "Epoch 151/200\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 954ms/step - accuracy: 0.9025 - loss: 0.2732 - val_accuracy: 0.5334 - val_loss: 1.7713\n",
      "Epoch 152/200\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 953ms/step - accuracy: 0.9069 - loss: 0.2761 - val_accuracy: 0.5282 - val_loss: 1.7707\n",
      "Epoch 153/200\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 952ms/step - accuracy: 0.8993 - loss: 0.2923 - val_accuracy: 0.5278 - val_loss: 1.7785\n",
      "Epoch 154/200\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 950ms/step - accuracy: 0.9002 - loss: 0.2752 - val_accuracy: 0.5329 - val_loss: 1.8582\n",
      "Epoch 155/200\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 950ms/step - accuracy: 0.9088 - loss: 0.2649 - val_accuracy: 0.5306 - val_loss: 1.7707\n",
      "Epoch 156/200\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 960ms/step - accuracy: 0.9090 - loss: 0.2750 - val_accuracy: 0.5289 - val_loss: 1.7729\n",
      "Epoch 157/200\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 958ms/step - accuracy: 0.9110 - loss: 0.2680 - val_accuracy: 0.5237 - val_loss: 1.7709\n",
      "Epoch 158/200\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 960ms/step - accuracy: 0.9106 - loss: 0.2651 - val_accuracy: 0.5283 - val_loss: 1.8249\n",
      "Epoch 159/200\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 962ms/step - accuracy: 0.9138 - loss: 0.2534 - val_accuracy: 0.5227 - val_loss: 1.8139\n",
      "Epoch 160/200\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 966ms/step - accuracy: 0.9091 - loss: 0.2685 - val_accuracy: 0.5277 - val_loss: 1.8041\n",
      "Epoch 161/200\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 965ms/step - accuracy: 0.9115 - loss: 0.2612 - val_accuracy: 0.5338 - val_loss: 1.7899\n",
      "Epoch 162/200\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 966ms/step - accuracy: 0.9169 - loss: 0.2705 - val_accuracy: 0.5311 - val_loss: 1.7924\n",
      "Epoch 163/200\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 968ms/step - accuracy: 0.9210 - loss: 0.2397 - val_accuracy: 0.5283 - val_loss: 1.8595\n",
      "Epoch 164/200\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 967ms/step - accuracy: 0.9198 - loss: 0.2402 - val_accuracy: 0.5298 - val_loss: 1.7665\n",
      "Epoch 165/200\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 965ms/step - accuracy: 0.9181 - loss: 0.2504 - val_accuracy: 0.5338 - val_loss: 1.7973\n",
      "Epoch 166/200\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 971ms/step - accuracy: 0.9163 - loss: 0.2494 - val_accuracy: 0.5333 - val_loss: 1.7901\n",
      "Epoch 167/200\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 970ms/step - accuracy: 0.9161 - loss: 0.2395 - val_accuracy: 0.5301 - val_loss: 1.7622\n",
      "Epoch 168/200\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 967ms/step - accuracy: 0.9092 - loss: 0.2596 - val_accuracy: 0.5286 - val_loss: 1.8189\n",
      "Epoch 169/200\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 966ms/step - accuracy: 0.9185 - loss: 0.2662 - val_accuracy: 0.5310 - val_loss: 1.8701\n",
      "Epoch 170/200\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 973ms/step - accuracy: 0.9136 - loss: 0.2608 - val_accuracy: 0.5310 - val_loss: 1.7891\n",
      "Epoch 171/200\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 971ms/step - accuracy: 0.9134 - loss: 0.2732 - val_accuracy: 0.5267 - val_loss: 1.7643\n",
      "Epoch 172/200\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 969ms/step - accuracy: 0.9177 - loss: 0.2511 - val_accuracy: 0.5300 - val_loss: 1.8395\n",
      "Epoch 173/200\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 969ms/step - accuracy: 0.9369 - loss: 0.1999 - val_accuracy: 0.5243 - val_loss: 1.8772\n",
      "Epoch 174/200\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 968ms/step - accuracy: 0.9225 - loss: 0.2490 - val_accuracy: 0.5272 - val_loss: 1.8218\n",
      "Epoch 175/200\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 968ms/step - accuracy: 0.9188 - loss: 0.2526 - val_accuracy: 0.5326 - val_loss: 1.8019\n",
      "Epoch 176/200\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 971ms/step - accuracy: 0.9194 - loss: 0.2394 - val_accuracy: 0.5320 - val_loss: 1.8397\n",
      "Epoch 177/200\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 968ms/step - accuracy: 0.9245 - loss: 0.2259 - val_accuracy: 0.5259 - val_loss: 1.7902\n",
      "Epoch 178/200\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 969ms/step - accuracy: 0.9195 - loss: 0.2473 - val_accuracy: 0.5340 - val_loss: 1.7845\n",
      "Epoch 179/200\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 966ms/step - accuracy: 0.9215 - loss: 0.2353 - val_accuracy: 0.5302 - val_loss: 1.8800\n",
      "Epoch 180/200\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 974ms/step - accuracy: 0.9231 - loss: 0.2280 - val_accuracy: 0.5238 - val_loss: 1.8555\n",
      "Epoch 181/200\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 969ms/step - accuracy: 0.9245 - loss: 0.2358 - val_accuracy: 0.5286 - val_loss: 1.8338\n",
      "Epoch 182/200\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 968ms/step - accuracy: 0.9268 - loss: 0.2237 - val_accuracy: 0.5314 - val_loss: 1.8259\n",
      "Epoch 183/200\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 974ms/step - accuracy: 0.9229 - loss: 0.2381 - val_accuracy: 0.5289 - val_loss: 1.8219\n",
      "Epoch 184/200\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 975ms/step - accuracy: 0.9329 - loss: 0.2046 - val_accuracy: 0.5309 - val_loss: 1.8975\n",
      "Epoch 185/200\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 968ms/step - accuracy: 0.9293 - loss: 0.2145 - val_accuracy: 0.5318 - val_loss: 1.7959\n",
      "Epoch 186/200\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 972ms/step - accuracy: 0.9235 - loss: 0.2198 - val_accuracy: 0.5306 - val_loss: 1.9108\n",
      "Epoch 187/200\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 969ms/step - accuracy: 0.9211 - loss: 0.2314 - val_accuracy: 0.5295 - val_loss: 1.8070\n",
      "Epoch 188/200\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 975ms/step - accuracy: 0.9276 - loss: 0.2199 - val_accuracy: 0.5333 - val_loss: 1.8559\n",
      "Epoch 189/200\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 968ms/step - accuracy: 0.9212 - loss: 0.2210 - val_accuracy: 0.5298 - val_loss: 1.8855\n",
      "Epoch 190/200\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 970ms/step - accuracy: 0.9298 - loss: 0.2118 - val_accuracy: 0.5274 - val_loss: 1.8871\n",
      "Epoch 191/200\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 970ms/step - accuracy: 0.9271 - loss: 0.2288 - val_accuracy: 0.5309 - val_loss: 1.8525\n",
      "Epoch 192/200\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 969ms/step - accuracy: 0.9387 - loss: 0.1920 - val_accuracy: 0.5285 - val_loss: 1.9123\n",
      "Epoch 193/200\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 969ms/step - accuracy: 0.9276 - loss: 0.2182 - val_accuracy: 0.5316 - val_loss: 1.8353\n",
      "Epoch 194/200\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 981ms/step - accuracy: 0.9322 - loss: 0.1922 - val_accuracy: 0.5249 - val_loss: 1.8544\n",
      "Epoch 195/200\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 981ms/step - accuracy: 0.9281 - loss: 0.2053 - val_accuracy: 0.5304 - val_loss: 1.8690\n",
      "Epoch 196/200\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 980ms/step - accuracy: 0.9296 - loss: 0.2044 - val_accuracy: 0.5270 - val_loss: 1.9047\n",
      "Epoch 197/200\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 977ms/step - accuracy: 0.9311 - loss: 0.2120 - val_accuracy: 0.5274 - val_loss: 1.8995\n",
      "Epoch 198/200\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 972ms/step - accuracy: 0.9338 - loss: 0.1962 - val_accuracy: 0.5293 - val_loss: 1.9642\n",
      "Epoch 199/200\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 970ms/step - accuracy: 0.9294 - loss: 0.2059 - val_accuracy: 0.5275 - val_loss: 1.8816\n",
      "Epoch 200/200\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 975ms/step - accuracy: 0.9280 - loss: 0.2154 - val_accuracy: 0.5272 - val_loss: 1.9190\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x2024be08ce0>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "model.fit(x=x_train, y=y_train, batch_size=128, epochs=200, validation_data=(x_test, y_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d8693b54",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    }
   ],
   "source": [
    "model_json = model.to_json()\n",
    "with open(\"emotiondetector.json\",'w') as json_file:\n",
    "    json_file.write(model_json)\n",
    "model.save(\"emotiondetector.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4cd9d351",
   "metadata": {},
   "outputs": [],
   "source": [
    "json_file = open(\"emotiondetector.json\", \"r\")\n",
    "model_json = json_file.read()\n",
    "json_file.close()\n",
    "model = model_from_json(model_json)\n",
    "model.load_weights(\"emotiondetector.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "94c9f4a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "label = ['angry','disgust','fear','happy','neutral','sad','surprise']\n",
    "\n",
    "def check(image):\n",
    "    img = load_img(image,grayscale =  True )\n",
    "    feature = np.array(img)\n",
    "    feature = feature.reshape(1,48,48,1)\n",
    "    return feature/255.0\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9969fb6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original image is of happy\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step\n",
      "model prediction is  happy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Hk200\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras_preprocessing\\image\\utils.py:107: UserWarning: grayscale is deprecated. Please use color_mode = \"grayscale\"\n",
      "  warnings.warn('grayscale is deprecated. Please use '\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "image = r'images\\Train\\happy\\14.jpg'\n",
    "print(\"original image is of happy\")\n",
    "img = check(image)\n",
    "pred = model.predict(img)\n",
    "pred_label = label[pred.argmax()]\n",
    "print(\"model prediction is \",pred_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b4a84b02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original image is of sad\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "model prediction is  happy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Hk200\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras_preprocessing\\image\\utils.py:107: UserWarning: grayscale is deprecated. Please use color_mode = \"grayscale\"\n",
      "  warnings.warn('grayscale is deprecated. Please use '\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x2028522c4a0>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "image =  r'images\\Train\\happy\\14.jpg'\n",
    "print(\"original image is of sad\")\n",
    "img = check(image)\n",
    "pred = model.predict(img)\n",
    "pred_label = label[pred.argmax()]\n",
    "print(\"model prediction is \",pred_label)\n",
    "plt.imshow(img.reshape(48,48),cmap='gray')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
